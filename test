package com.schwab.cdt.spos.source.config;

import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Configuration;

import java.util.List;

@Configuration
@ConfigurationProperties(prefix = "csv-to-avro")
public class CsvToAvroConfig {

    private List<Conversion> conversions;

    public List<Conversion> getConversions() {
        return conversions;
    }

    public void setConversions(List<Conversion> conversions) {
        this.conversions = conversions;
    }

    public static class Conversion {
        private String name;
        private String sourceFile;
        private String avroSchema;
        private String targetAvroFile;
        private String delimiter;

        // Getters and setters...
    }
}











package com.schwab.cdt.spos.source.converter;

import org.apache.avro.Schema;
import org.apache.avro.file.DataFileWriter;
import org.apache.avro.generic.*;
import org.apache.avro.io.DatumWriter;
import org.springframework.stereotype.Component;

import java.io.*;
import java.util.Arrays;
import java.util.List;

@Component
public class CsvToAvroConverter {

    public void convertCsvToAvro(String csvFilePath, String schemaFilePath, String avroFilePath, String delimiter) throws IOException {
        // Load Avro schema from file
        Schema schema = new Schema.Parser().parse(new File(schemaFilePath));

        // Create Avro writer
        DatumWriter<GenericRecord> datumWriter = new GenericDatumWriter<>(schema);
        try (DataFileWriter<GenericRecord> dataFileWriter = new DataFileWriter<>(datumWriter)) {
            dataFileWriter.create(schema, new File(avroFilePath));

            // Open CSV file and read records
            try (BufferedReader br = new BufferedReader(new FileReader(csvFilePath))) {
                String line;
                List<String> headers = null;

                while ((line = br.readLine()) != null) {
                    String[] values = line.split(delimiter);
                    if (headers == null) {
                        // First line contains headers
                        headers = Arrays.asList(values);
                    } else {
                        // Create Avro record and set fields
                        GenericRecord record = new GenericData.Record(schema);
                        for (int i = 0; i < values.length; i++) {
                            // Handle different data types based on schema
                            Schema.Field field = schema.getFields().get(i);
                            Object convertedValue = convertValue(values[i], field.schema());
                            record.put(headers.get(i), convertedValue);
                        }
                        dataFileWriter.append(record);
                    }
                }
            }
        }
    }

    private Object convertValue(String value, Schema fieldSchema) {
        // Implement type conversion based on field schema
        switch (fieldSchema.getType()) {
            case INT:
                return Integer.parseInt(value);
            case LONG:
                return Long.parseLong(value);
            case FLOAT:
                return Float.parseFloat(value);
            case DOUBLE:
                return Double.parseDouble(value);
            case BOOLEAN:
                return Boolean.parseBoolean(value);
            case STRING:
                return value;
            case BYTES:
                return value.getBytes();
            // Handle other types as needed
            default:
                return value;
        }
    }
}












package com.schwab.cdt.spos.source.job.step;

import com.schwab.cdt.spos.source.config.CsvToAvroConfig;
import com.schwab.cdt.spos.source.converter.CsvToAvroConverter;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.stereotype.Component;

import java.io.IOException;

@Component
public class CsvToAvroConversionStep {

    private final StepBuilderFactory stepBuilderFactory;
    private final CsvToAvroConverter csvToAvroConverter;
    private final CsvToAvroConfig csvToAvroConfig;

    public CsvToAvroConversionStep(StepBuilderFactory stepBuilderFactory,
                                   CsvToAvroConverter csvToAvroConverter,
                                   CsvToAvroConfig csvToAvroConfig) {
        this.stepBuilderFactory = stepBuilderFactory;
        this.csvToAvroConverter = csvToAvroConverter;
        this.csvToAvroConfig = csvToAvroConfig;
    }

    public Step csvToAvroConversionStep() {
        return stepBuilderFactory.get("csvToAvroConversionStep")
            .tasklet((contribution, chunkContext) -> {
                // Iterate over all conversions defined in YAML
                for (CsvToAvroConfig.Conversion conversion : csvToAvroConfig.getConversions()) {
                    try {
                        csvToAvroConverter.convertCsvToAvro(
                            conversion.getSourceFile(),
                            conversion.getAvroSchema(),
                            conversion.getTargetAvroFile(),
                            conversion.getDelimiter()
                        );
                    } catch (IOException e) {
                        throw new RuntimeException("Failed to convert CSV to Avro: " + e.getMessage(), e);
                    }
                }
                return RepeatStatus.FINISHED;
            })
            .build();
    }
}











package com.schwab.cdt.spos.source.job;

import com.schwab.cdt.spos.source.job.step.CsvToAvroConversionStep;
import org.springframework.batch.core.Job;
import org.springframework.batch.core.job.builder.JobBuilder;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class DataIngestionJobBuilder {

    private final JobRepository jobRepository;
    private final DataIngestionStepBuilder dataIngestionStepBuilder;
    private final DataIngestionJobListener dataIngestionJobListener;
    private final CsvToAvroConversionStep csvToAvroConversionStep;

    public DataIngestionJobBuilder(DataIngestionStepBuilder dataIngestionStepBuilder,
                                   JobRepository jobRepository,
                                   DataIngestionJobListener dataIngestionJobListener,
                                   CsvToAvroConversionStep csvToAvroConversionStep) {
        this.jobRepository = jobRepository;
        this.dataIngestionStepBuilder = dataIngestionStepBuilder;
        this.dataIngestionJobListener = dataIngestionJobListener;
        this.csvToAvroConversionStep = csvToAvroConversionStep;
    }

    @Bean(name = "csvToAvroDataIngestionJob")
    public Job csvToAvroDataIngestionJob() {
        return new JobBuilder("csvToAvroDataIngestionJob", jobRepository)
            .incrementer(new RunIdIncrementer())
            .listener(dataIngestionJobListener)
            .preventRestart()
            .start(csvToAvroConversionStep.csvToAvroConversionStep())
            .next(dataIngestionStepBuilder.avroDataIngestionStep())
            .build();
    }
}











public JobExecution start(String jobName, String executionDate) throws Exception {
    Job job;
    var jobMetadata = jobLookUpWithMetadata(jobName);
    JobParametersBuilder builder = new JobParametersBuilder()
        .addLocalDateTime("jobDateTime", LocalDateTime.now().atZone(ZoneId.of("America/New_York")).toLocalDateTime())
        .addString("jobName", jobMetadata.get("jobName"))
        .addString("definition", jobMetadata.get("definition"))
        .addString("asOfDate", executionDate);

    switch (jobMetadata.get("definition").toLowerCase()) {
        case "csv_to_avro":
            job = csvToAvroDataIngestionJob();
            break;
        case "avro_to_postgres":
            job = avroDataIngestionJob();
            break;
        // Handle other cases
        default:
            throw new UnsupportedOperationException("Unsupported job definition: " + jobMetadata.get("definition"));
    }
    return jobLauncher.run(job, builder.toJobParameters());
}
